{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d436e15-4d6c-4766-805b-46a7b8747304",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ElasticNet Regresyon\n",
    "* Amaç hata  kareler toplamını minimize eden katsayıları bu katsayılara bir ceza uygulayarak bulmaktır.\n",
    "* ElasticNet L1 ve L2 yaklaşımlarını birleştirir.\n",
    "* Zou & Hastiie 2005\n",
    "-----------------------------------------\n",
    "$ SSE_{net} = \\Sigma(y_i - \\hat{y}_{ij})^2 + \\lambda_1 \\Sigma{\\beta_j^2}+ \\lambda_2 \\Sigma{|\\beta_j|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e31fc8-2850-4a55-ba47-14c8fb0e4808",
   "metadata": {},
   "source": [
    "##### ElasticNet Regresyon Model ve Tahmini\n",
    "* Gerekli küt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e40315-63ca-44cc-98cd-47fd8f1c48c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7caa91eb-999e-4422-82ad-e2d98979f0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hitters.csv')\n",
    "df = df.dropna()\n",
    "y= df['Salary']\n",
    "dms = pd.get_dummies(df[['League', 'Division','NewLeague']])\n",
    "X_= df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1)\n",
    "X= pd.concat([X_,dms[['League_N','Division_W','NewLeague_N']]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2002df7a-828e-4bb8-93bc-029e00ce4dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycanf\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.488e+06, tolerance: 3.899e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "enet_model = ElasticNet().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "928f091f-5bad-4418-8095-cdc74b944244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.86256172,   8.70489065,   5.10426375,  -2.89875799,\n",
       "        -1.28642985,   5.24343682,   6.04480276,  -0.14701495,\n",
       "        -0.21566628,  -0.7897201 ,   1.80813117,   0.80914508,\n",
       "        -0.61262382,   0.26816203,   0.27172387,  -0.36530729,\n",
       "        19.2186222 , -31.16586592,   8.98369938])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.coef_ # katsayılar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfe793bb-0be9-4d55-bf9c-e46ecc33abe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.465955602114036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.intercept_ # sabit terimi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f0a12-9af7-438a-ab1a-761bbe0d9024",
   "metadata": {},
   "source": [
    "# tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e413ab2-4acb-4368-a48a-c50315fec223",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 325.74706292,  776.06632333,  522.86508419,  107.64091955,\n",
       "        449.03139566,  997.76095723,   99.78828622,  311.33763086,\n",
       "        418.50335021,  879.9502608 , 1628.05423879,  831.63172575,\n",
       "        909.34196881,  715.67274292,  601.33595953,  657.40417507,\n",
       "       1068.2110763 ,  149.6849625 ,  190.40513329,  385.31235163,\n",
       "        752.37991572, 1022.76166475,  486.94874949,  349.7945189 ,\n",
       "         69.28225147,  783.98489255,  551.11613877,  205.84644387,\n",
       "        367.25234577,  303.22135065,   98.44933333,  533.19866378,\n",
       "       1000.16419322,  245.20490159,  448.10920305,  401.93188524,\n",
       "        457.71559572,  713.00914559,  333.18157434,  235.45584771,\n",
       "        210.52615243,  309.20890759,  190.6560382 ,  183.01443111,\n",
       "        238.19688018, 1080.44877923,  380.19569305,  551.45922356,\n",
       "        278.3820838 ,  338.53829531])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.predict(X_train) [0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3f720c6-c90b-49ef-866e-f5b429b782c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = enet_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5541e015-e57b-4f0c-ba16-e5b3a9051b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.16765481812484"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred)) ## ilkel RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60fd84db-6940-4bb3-8378-61057d9cfc32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4107022246932679"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb49ace-03af-47e7-9825-05e1d3b41169",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69c27c32-e1c0-4ec2-8c92-0d5c264607f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enet_cv_model = ElasticNetCV(cv=10).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8f72d36-7595-4a71-8b78-070f102124a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5230.764736479864"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f6f9cc8-c0b8-4412-89f8-1757108720ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-38.519405583943126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d6ae25d-ff3a-4c4f-8d9e-d50c47f1bd15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62845434,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.09788752,  0.        ,\n",
       "        0.27265769,  0.19270075,  0.00758665,  0.3106529 ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0da1c-447e-44ba-a3e3-10c1cf8390a7",
   "metadata": {},
   "source": [
    "#### final modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b220a307-99fb-4322-97ce-d19dc625ef59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enet_tuned = ElasticNet(alpha=enet_cv_model.alpha_).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ef394d0-beee-4081-8b78-e2d78282d18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = enet_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1908ad14-edf5-413e-a6a6-73a55ca97b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.15280563218795"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b30a5f43-6eff-44e7-9891-5f398e5a08da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mElasticNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cyclic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Linear regression with combined L1 and L2 priors as regularizer.\n",
       "\n",
       "Minimizes the objective function::\n",
       "\n",
       "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
       "        + alpha * l1_ratio * ||w||_1\n",
       "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
       "\n",
       "If you are interested in controlling the L1 and L2 penalty\n",
       "separately, keep in mind that this is equivalent to::\n",
       "\n",
       "        a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
       "\n",
       "where::\n",
       "\n",
       "        alpha = a + b and l1_ratio = a / (a + b)\n",
       "\n",
       "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
       "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
       "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
       "unless you supply your own sequence of alpha.\n",
       "\n",
       "Read more in the :ref:`User Guide <elastic_net>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "alpha : float, default=1.0\n",
       "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
       "    See the notes for the exact mathematical meaning of this\n",
       "    parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
       "    solved by the :class:`LinearRegression` object. For numerical\n",
       "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
       "    Given this, you should use the :class:`LinearRegression` object.\n",
       "\n",
       "l1_ratio : float, default=0.5\n",
       "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
       "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
       "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
       "    combination of L1 and L2.\n",
       "\n",
       "fit_intercept : bool, default=True\n",
       "    Whether the intercept should be estimated or not. If ``False``, the\n",
       "    data is assumed to be already centered.\n",
       "\n",
       "precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
       "    Whether to use a precomputed Gram matrix to speed up\n",
       "    calculations. The Gram matrix can also be passed as argument.\n",
       "    For sparse input this option is always ``False`` to preserve sparsity.\n",
       "\n",
       "max_iter : int, default=1000\n",
       "    The maximum number of iterations.\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If ``True``, X will be copied; else, it may be overwritten.\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    The tolerance for the optimization: if the updates are\n",
       "    smaller than ``tol``, the optimization code checks the\n",
       "    dual gap for optimality and continues until it is smaller\n",
       "    than ``tol``, see Notes below.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to ``True``, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive.\n",
       "\n",
       "random_state : int, RandomState instance, default=None\n",
       "    The seed of the pseudo random number generator that selects a random\n",
       "    feature to update. Used when ``selection`` == 'random'.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "selection : {'cyclic', 'random'}, default='cyclic'\n",
       "    If set to 'random', a random coefficient is updated every iteration\n",
       "    rather than looping over features sequentially by default. This\n",
       "    (setting to 'random') often leads to significantly faster convergence\n",
       "    especially when tol is higher than 1e-4.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
       "    Parameter vector (w in the cost function formula).\n",
       "\n",
       "sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
       "    Sparse representation of the `coef_`.\n",
       "\n",
       "intercept_ : float or ndarray of shape (n_targets,)\n",
       "    Independent term in decision function.\n",
       "\n",
       "n_iter_ : list of int\n",
       "    Number of iterations run by the coordinate descent solver to reach\n",
       "    the specified tolerance.\n",
       "\n",
       "dual_gap_ : float or ndarray of shape (n_targets,)\n",
       "    Given param alpha, the dual gaps at the end of the optimization,\n",
       "    same shape as each observation of y.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ElasticNetCV : Elastic net model with best model selection by\n",
       "    cross-validation.\n",
       "SGDRegressor : Implements elastic net regression with incremental training.\n",
       "SGDClassifier : Implements logistic regression with elastic net penalty\n",
       "    (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
       "\n",
       "Notes\n",
       "-----\n",
       "To avoid unnecessary memory duplication the X argument of the fit method\n",
       "should be directly passed as a Fortran-contiguous numpy array.\n",
       "\n",
       "The precise stopping criteria based on `tol` are the following: First, check that\n",
       "that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
       "is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
       "If so, then additionally check whether the dual gap is smaller than `tol` times\n",
       ":math:`||y||_2^2 / n_{      ext{samples}}`.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.linear_model import ElasticNet\n",
       ">>> from sklearn.datasets import make_regression\n",
       "\n",
       ">>> X, y = make_regression(n_features=2, random_state=0)\n",
       ">>> regr = ElasticNet(random_state=0)\n",
       ">>> regr.fit(X, y)\n",
       "ElasticNet(random_state=0)\n",
       ">>> print(regr.coef_)\n",
       "[18.83816048 64.55968825]\n",
       ">>> print(regr.intercept_)\n",
       "1.451...\n",
       ">>> print(regr.predict([[0, 0]]))\n",
       "[1.451...]\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\ycanf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     Lasso"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b98c9-9423-4d1b-8cd3-0c3f3fbeeb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
